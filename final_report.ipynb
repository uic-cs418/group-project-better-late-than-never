{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d43beeb1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "<h1>Yelp Review Aggregator</h1>\n",
    "\n",
    "Team: Better Late than never"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211d762f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "<h3>Intro</h3>\n",
    "\n",
    "- Motivations/Stakeholders\n",
    "- Hypotheses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39bfd88",
   "metadata": {},
   "source": [
    "<h3>Data</h3>\n",
    "\n",
    "Our project used the Yelp Open dataset, a public dataset for educational use. It spans over 150K businesses, over 7 million reviews, and almost 2 million users. The dataset covers 11 metropolitan areas over 20+ states in the United States. Reviews were collected between Feb 16, 2005 and Jan 19, 2022.\n",
    "\n",
    "To clean the data, we first removed all non-restaurants from the dataset. Next, we removed all restaurants with less than 30 reviews. We then removed all reviews not pertaining to the restaurants left in the dataset. Lastly, we removed all users who did not write a review about the remaining restaurants. The following code cell outputs the results of cleaning (the dataset is too large to submit)\n",
    "\n",
    "Source: https://business.yelp.com/data/resources/open-dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1418639a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of restaurants after cleaning: 27894\n",
      "Number of reviews after cleaning: 4371282\n",
      "Number of users after cleaning: 1379980\n"
     ]
    }
   ],
   "source": [
    "import data_cleaning as clean\n",
    "chunk_size = 100_000\n",
    "\n",
    "# We assume that the raw yelp dataset has been extracted to the folder 'data'\n",
    "restaurants_df = clean.filter_business_data(\"data/yelp_academic_dataset_business.json\", chunk_size)\n",
    "reviews_df = clean.filter_review_data(\"data/yelp_academic_dataset_review.json\", restaurants_df, chunk_size)\n",
    "users_df = clean.filter_user_data(\"data/yelp_academic_dataset_user.json\", reviews_df, chunk_size)\n",
    "\n",
    "print(f'Number of restaurants after cleaning: {restaurants_df.shape[0]}')\n",
    "print(f'Number of reviews after cleaning: {reviews_df.shape[0]}')\n",
    "print(f'Number of users after cleaning: {users_df.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58524099",
   "metadata": {},
   "source": [
    "Text - EDA - Distribution of Reviews and Review Scores\n",
    "\n",
    "TODO: Describe viz and takeaways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1876b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run code for viz 1 - distribution of review scores\n",
    "\n",
    "## Run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c451b3",
   "metadata": {},
   "source": [
    "Text - EDA #1 - Heatmap of average score prices\n",
    "\n",
    "TODO: Describe viz and takeaways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302464ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## output viz\n",
    "\n",
    "# TODO: Harket - create .py file to output viz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ea3ff6",
   "metadata": {},
   "source": [
    "Text - EDA #2 - Average score vs price\n",
    "\n",
    "TODO: Describe viz and takeaways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a644314",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Output viz\n",
    "\n",
    "## TODO: Sonya - Create .py file to output viz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ef34f2",
   "metadata": {},
   "source": [
    "<h3>ML #1 - Binary Classification of Review Text</h3>\n",
    "\n",
    "After looking at review scores, we turned to review text. We wanted to see if the text of a review aligned with the review's score, bias and all. To do this, we created a machine learning model to classify review text as 'Bad' (score < 4) or 'Good' (score >= 4). We trained a SVC with 50K reviews using the cuml library, a GPU-accelerated version of sklearn. Our features were a matrix of TF-IDF vectors. To benchmark, we compared the accuracy of our model to a majority label classifier using 5K reviews unused in training. We cross-validated to find the most effective SVC kernel and number of data points, but didn't find a significant difference in results from our tuning\n",
    "\n",
    "TODO: Describe results and takeaway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a757093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuML: Installed accelerator for sklearn.\n",
      "cuML: Successfully initialized accelerator.\n",
      "Benchmark accuracy for our model to beat: 0.6928066037735849\n",
      "Model Accuracy: 0.8876768867924528\n"
     ]
    }
   ],
   "source": [
    "import text_analysis as ml\n",
    "benchmark_size = 5000\n",
    "\n",
    "train_X, train_, binary_tfidf, binary_classifier = ml.load_model(\"binary\")\n",
    "test_X, test_y = ml.create_binary_test_data(reviews_df, benchmark_size, binary_tfidf)\n",
    "\n",
    "ml.benchmark(test_X, test_y)\n",
    "ml.evaluate_classifier(binary_classifier, test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528c88d7",
   "metadata": {},
   "source": [
    "Text - ML #2 - Multi-classification of reviews\n",
    "\n",
    "TODO: Describe study and takeaways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb80a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Load model, benchmark on test data, and evaluate on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e37b94",
   "metadata": {},
   "source": [
    "Text - App Demo\n",
    "\n",
    "https://yelp-recs.crowsnet.io\n",
    "\n",
    "TODO: Describe app and data pulling/cleaning process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57ebbac",
   "metadata": {},
   "source": [
    "Text - Results\n",
    "\n",
    "1. Yelp data is biased\n",
    "2. Yelp bias is user input, at least in part"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
