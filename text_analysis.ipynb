{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e1ee211-43e0-41f8-b20f-530bcf9089a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/chasty2/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/chasty2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/chasty2/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/chasty2/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/chasty2/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/chasty2/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/chasty2/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package tagsets_json to\n",
      "[nltk_data]     /home/chasty2/nltk_data...\n",
      "[nltk_data]   Package tagsets_json is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import sklearn\n",
    "import string\n",
    "import warnings\n",
    "import re\n",
    "from scipy import sparse\n",
    "from IPython.display import display, Latex, Markdown\n",
    "warnings.filterwarnings('ignore')\n",
    "import data_cleaning as dc\n",
    "import review_score_analysis as rs\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('tagsets_json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf9e59f1-13aa-4a46-a130-b714b8a6eb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Text Processing\n",
    "\n",
    "def process(text, lemmatizer=nltk.stem.wordnet.WordNetLemmatizer()):\n",
    "    \"\"\" Normalizes case and handles punctuation\n",
    "    Inputs:\n",
    "        text: str: raw text\n",
    "        lemmatizer: an instance of a class implementing the lemmatize() method\n",
    "                    (the default argument is of type nltk.stem.wordnet.WordNetLemmatizer)\n",
    "    Outputs:\n",
    "        list(str): tokenized text\n",
    "    \"\"\"\n",
    "    posMapping = {\n",
    "    # \"First_Letter by nltk.pos_tag\":\"POS_for_lemmatizer\"\n",
    "        \"N\":'n',\n",
    "        \"V\":'v',\n",
    "        \"J\":'a',\n",
    "        \"R\":'r'\n",
    "    }\n",
    "\n",
    "    \n",
    "    # Create regex to catch URLs\n",
    "    url_regex = re.compile(r'''(\n",
    "        (?:https?://)?        ## Optionally match http:// or https://\n",
    "        (?:www\\.)?            ## Optionally match www.\n",
    "        [\\w.-]+\\.\\w+          ## Match multiple domains (example.com or sub.domain.co.uk)\n",
    "        (?:[/?#][^\\s]*)?      ## Optionally match paths, queries, or fragments\n",
    "    )''', re.VERBOSE)\n",
    "    \n",
    "    ### Process string\n",
    "    # Remove URLs\n",
    "    text = url_regex.sub(\"\", text).strip()\n",
    "    # Remove all ('s) e.g. she's -> she\n",
    "    text = re.sub(\"'s\", \"\", text).strip()\n",
    "    # Omit other apostrophes e.g. don't -> dont\n",
    "    text = re.sub(\"'\", \"\", text).strip()\n",
    "    # swap all other punctuation with ' '\n",
    "    text = text.translate(str.maketrans(string.punctuation, ' '*len(string.punctuation)))\n",
    "    # Set to lowercase\n",
    "    text = str.lower(text)\n",
    "    \n",
    "    ### Process tokens\n",
    "    # tokenize string\n",
    "    tokenized_text = nltk.word_tokenize(text)\n",
    "    # Tag tokens\n",
    "    tokenized_text = nltk.pos_tag(tokenized_text)\n",
    "    # lemmatize tokens, converting pos tags based on mappings above\n",
    "    lemmatized_tokens = []\n",
    "    for word,tag in tokenized_text:\n",
    "        try:\n",
    "            lemma = lemmatizer.lemmatize(word, pos=posMapping[tag[0]])\n",
    "        except KeyError:\n",
    "            # Anything not caught by posMapping dict has pos 'n'\n",
    "            lemma = lemmatizer.lemmatize(word, pos='n')\n",
    "        # except:\n",
    "        #     # Ignore other exceptions\n",
    "        #     continue\n",
    "        lemmatized_tokens.append(lemma)\n",
    "\n",
    "    return lemmatized_tokens\n",
    "\n",
    "def process_all(df, lemmatizer=nltk.stem.wordnet.WordNetLemmatizer()):\n",
    "    \"\"\" process all text in the dataframe using process() function.\n",
    "    Inputs\n",
    "        df: pd.DataFrame: dataframe containing a column 'text' loaded from the CSV file\n",
    "        lemmatizer: an instance of a class implementing the lemmatize() method\n",
    "                    (the default argument is of type nltk.stem.wordnet.WordNetLemmatizer)\n",
    "    Outputs\n",
    "        pd.DataFrame: dataframe in which the values of text column have been changed from str to list(str),\n",
    "                        the output from process() function. Other columns are unaffected.\n",
    "    \"\"\"\n",
    "    df['text'] = df['text'].apply(process)\n",
    "    return df\n",
    "\n",
    "### Feature Construction\n",
    "def create_features(processed_reviews, stop_words):\n",
    "    \"\"\" creates the feature matrix using the processed review text\n",
    "    Inputs:\n",
    "        processed_reviews: pd.DataFrame: processed reviews read from train/test  file, containing the column 'text'\n",
    "        stop_words: list(str): stop_words by nltk stopwords (after processing)\n",
    "    Outputs:\n",
    "        sklearn.feature_extraction.text.TfidfVectorizer: the TfidfVectorizer object used\n",
    "            we need this to tranform test reviews in the same way as train reviews\n",
    "        scipy.sparse.csr.csr_matrix: sparse bag-of-words TF-IDF feature matrix\n",
    "    \"\"\"\n",
    "    # Convert processed tweets text values to list of strings, with one tweet per string\n",
    "    reviews_list = processed_reviews[\"text\"].apply(lambda x: ' '.join(x)).tolist()\n",
    "\n",
    "    # Learn vocabulary and idf, return document-term matrix\n",
    "    tfidf = sklearn.feature_extraction.text.TfidfVectorizer(\n",
    "        min_df=2, lowercase=False, stop_words=stop_words\n",
    "    )\n",
    "    X = tfidf.fit_transform(reviews_list)\n",
    "\n",
    "    return tfidf, X\n",
    "\n",
    "\n",
    "def create_labels(avg_scores_df):\n",
    "    \"\"\" creates the class labels from screen_name\n",
    "    Inputs:\n",
    "        avg_scores_df: pd.DataFrame: restaurants read from training df, containing the column 'avg_review_score'\n",
    "    Outputs:\n",
    "        numpy.ndarray(int): series of class labels \n",
    "        1 for restaurants with avg_review_score >= 4.5\n",
    "        0 otherwise\n",
    "    \"\"\"\n",
    "    # Apply vectorized  operation to score restaurants\n",
    "    label_series = (avg_scores_df['avg_review_score'] >= 4.5).astype(int)\n",
    "\n",
    "    return label_series\n",
    "\n",
    "### Classification\n",
    "def learn_classifier(X_train, y_train, kernel):\n",
    "    \"\"\" learns a classifier from the input features and labels using the kernel function supplied\n",
    "    Inputs:\n",
    "        X_train: scipy.sparse.csr.csr_matrix: sparse matrix of features, output of create_features()\n",
    "        y_train: numpy.ndarray(int): dense binary vector of class labels, output of create_labels()\n",
    "        kernel: str: kernel function to be used with classifier. [linear|poly|rbf|sigmoid]\n",
    "    Outputs:\n",
    "        sklearn.svm.SVC: classifier learnt from data\n",
    "    \"\"\"\n",
    "    \n",
    "    classifier = sklearn.svm.SVC(kernel=kernel)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    return classifier\n",
    "\n",
    "def evaluate_classifier(classifier, X_validation, y_validation):\n",
    "    \"\"\" evaluates a classifier based on a supplied validation data\n",
    "    Inputs:\n",
    "        classifier: sklearn.svm.classes.SVC: classifer to evaluate\n",
    "        X_validation: scipy.sparse.csr.csr_matrix: sparse matrix of features\n",
    "        y_validation: numpy.ndarray(int): dense binary vector of class labels\n",
    "    Outputs:\n",
    "        double: accuracy of classifier on the validation data\n",
    "    \"\"\"\n",
    "    # Run classification of predicted political party based on each tweet\n",
    "    predicted_labels = classifier.predict(X_validation)\n",
    "\n",
    "    # Calculate accuracy of predictions\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_validation, predicted_labels)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "759db37f-52ae-43a6-b78e-b2c7f321e230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataframes\n",
    "chunk_size = 100_000\n",
    "restaurants_df = dc.load(\"data/filtered_restaurants.json\", chunk_size)\n",
    "reviews_df = dc.load(\"data/filtered_reviews.json\", chunk_size)\n",
    "avg_scores = rs.calculate_average_review_score(restaurants_df, reviews_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ee99de2-f185-48bb-8d38-d2bff4180f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>attributes</th>\n",
       "      <th>categories</th>\n",
       "      <th>hours</th>\n",
       "      <th>avg_review_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MTSW4McQd7CbVtyjqoe9mw</td>\n",
       "      <td>St Honore Pastries</td>\n",
       "      <td>935 Race St</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>PA</td>\n",
       "      <td>19107</td>\n",
       "      <td>39.955505</td>\n",
       "      <td>-75.155564</td>\n",
       "      <td>4.0</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RestaurantsDelivery': 'False', 'OutdoorSeati...</td>\n",
       "      <td>Restaurants, Food, Bubble Tea, Coffee &amp; Tea, B...</td>\n",
       "      <td>{'Monday': '7:0-20:0', 'Tuesday': '7:0-20:0', ...</td>\n",
       "      <td>4.057471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0bPLkL0QhhPO5kt1_EXmNQ</td>\n",
       "      <td>Zio's Italian Market</td>\n",
       "      <td>2575 E Bay Dr</td>\n",
       "      <td>Largo</td>\n",
       "      <td>FL</td>\n",
       "      <td>33771</td>\n",
       "      <td>27.916116</td>\n",
       "      <td>-82.760461</td>\n",
       "      <td>4.5</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>{'OutdoorSeating': 'False', 'RestaurantsGoodFo...</td>\n",
       "      <td>Food, Delis, Italian, Bakeries, Restaurants</td>\n",
       "      <td>{'Monday': '10:0-18:0', 'Tuesday': '10:0-20:0'...</td>\n",
       "      <td>4.386792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MUTTqe8uqyMdBl186RmNeA</td>\n",
       "      <td>Tuna Bar</td>\n",
       "      <td>205 Race St</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>PA</td>\n",
       "      <td>19106</td>\n",
       "      <td>39.953949</td>\n",
       "      <td>-75.143226</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RestaurantsReservations': 'True', 'Restauran...</td>\n",
       "      <td>Sushi Bars, Restaurants, Japanese</td>\n",
       "      <td>{'Tuesday': '13:30-22:0', 'Wednesday': '13:30-...</td>\n",
       "      <td>4.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROeacJQwBeh05Rqg7F6TCg</td>\n",
       "      <td>BAP</td>\n",
       "      <td>1224 South St</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>PA</td>\n",
       "      <td>19147</td>\n",
       "      <td>39.943223</td>\n",
       "      <td>-75.162568</td>\n",
       "      <td>4.5</td>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>{'NoiseLevel': 'u'quiet'', 'GoodForMeal': '{'d...</td>\n",
       "      <td>Korean, Restaurants</td>\n",
       "      <td>{'Monday': '11:30-20:30', 'Tuesday': '11:30-20...</td>\n",
       "      <td>4.317308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WKMJwqnfZKsAae75RMP6jA</td>\n",
       "      <td>Roast Coffeehouse and Wine Bar</td>\n",
       "      <td>10359 104 Street NW</td>\n",
       "      <td>Edmonton</td>\n",
       "      <td>AB</td>\n",
       "      <td>T5J 1B9</td>\n",
       "      <td>53.546045</td>\n",
       "      <td>-113.499169</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>{'OutdoorSeating': 'False', 'Caters': 'True', ...</td>\n",
       "      <td>Coffee &amp; Tea, Food, Cafes, Bars, Wine Bars, Re...</td>\n",
       "      <td>{'Monday': '8:0-18:0', 'Tuesday': '8:0-18:0', ...</td>\n",
       "      <td>3.825000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                            name  \\\n",
       "0  MTSW4McQd7CbVtyjqoe9mw              St Honore Pastries   \n",
       "1  0bPLkL0QhhPO5kt1_EXmNQ            Zio's Italian Market   \n",
       "2  MUTTqe8uqyMdBl186RmNeA                        Tuna Bar   \n",
       "3  ROeacJQwBeh05Rqg7F6TCg                             BAP   \n",
       "4  WKMJwqnfZKsAae75RMP6jA  Roast Coffeehouse and Wine Bar   \n",
       "\n",
       "               address          city state postal_code   latitude   longitude  \\\n",
       "0          935 Race St  Philadelphia    PA       19107  39.955505  -75.155564   \n",
       "1        2575 E Bay Dr         Largo    FL       33771  27.916116  -82.760461   \n",
       "2          205 Race St  Philadelphia    PA       19106  39.953949  -75.143226   \n",
       "3        1224 South St  Philadelphia    PA       19147  39.943223  -75.162568   \n",
       "4  10359 104 Street NW      Edmonton    AB     T5J 1B9  53.546045 -113.499169   \n",
       "\n",
       "   stars  review_count  is_open  \\\n",
       "0    4.0            80        1   \n",
       "1    4.5           100        0   \n",
       "2    4.0           245        1   \n",
       "3    4.5           205        1   \n",
       "4    4.0            40        0   \n",
       "\n",
       "                                          attributes  \\\n",
       "0  {'RestaurantsDelivery': 'False', 'OutdoorSeati...   \n",
       "1  {'OutdoorSeating': 'False', 'RestaurantsGoodFo...   \n",
       "2  {'RestaurantsReservations': 'True', 'Restauran...   \n",
       "3  {'NoiseLevel': 'u'quiet'', 'GoodForMeal': '{'d...   \n",
       "4  {'OutdoorSeating': 'False', 'Caters': 'True', ...   \n",
       "\n",
       "                                          categories  \\\n",
       "0  Restaurants, Food, Bubble Tea, Coffee & Tea, B...   \n",
       "1        Food, Delis, Italian, Bakeries, Restaurants   \n",
       "2                  Sushi Bars, Restaurants, Japanese   \n",
       "3                                Korean, Restaurants   \n",
       "4  Coffee & Tea, Food, Cafes, Bars, Wine Bars, Re...   \n",
       "\n",
       "                                               hours  avg_review_score  \n",
       "0  {'Monday': '7:0-20:0', 'Tuesday': '7:0-20:0', ...          4.057471  \n",
       "1  {'Monday': '10:0-18:0', 'Tuesday': '10:0-20:0'...          4.386792  \n",
       "2  {'Tuesday': '13:30-22:0', 'Wednesday': '13:30-...          4.200000  \n",
       "3  {'Monday': '11:30-20:30', 'Tuesday': '11:30-20...          4.317308  \n",
       "4  {'Monday': '8:0-18:0', 'Tuesday': '8:0-18:0', ...          3.825000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_scores.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d964a9fe-d97b-42f0-916c-53bd56f5bdce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [if, you, decide, to, eat, here, just, be, awa...\n",
       "1    [family, diner, have, the, buffet, eclectic, a...\n",
       "2    [wow, yummy, different, delicious, our, favori...\n",
       "3    [cute, interior, and, owner, give, u, tour, of...\n",
       "4    [i, be, a, long, term, frequent, customer, of,...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Build and Test Model\n",
    "\n",
    "# This takes a while, so we're gonna use 100K reviews for testing\n",
    "processed_reviews = process_all(reviews_df[0:99999])\n",
    "processed_reviews[\"text\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8633e1e4-113c-4393-93f5-10009a4e1bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=nltk.corpus.stopwords.words('english')\n",
    "processed_stopwords = list(np.concatenate([process(word) for word in stopwords]))\n",
    "(tfidf, X) = create_features(processed_reviews, processed_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15866fd-2655-44a4-b50e-a2edbfea03b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = create_labels()\n",
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
